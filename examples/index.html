<!DOCTYPE html>

<html class="writer-html5" lang="en">
<head>
<meta charset="utf-8"/>
<meta content="IE=edge" http-equiv="X-UA-Compatible"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/><link href="https://vuw-research-computing.github.io/raapoi-docs/examples/" rel="canonical"/>
<link href="../img/favicon.ico" rel="shortcut icon"/>
<title>Examples - Rāpoi Cluster Documentation</title>
<link href="../css/theme.css" rel="stylesheet"/>
<link href="../css/theme_extra.css" rel="stylesheet"/>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/styles/github.min.css" rel="stylesheet"/>
<link href="../extra.css" rel="stylesheet"/>
<script>
        // Current page data
        var mkdocs_page_name = "Examples";
        var mkdocs_page_input_path = "examples.md";
        var mkdocs_page_url = "/raapoi-docs/examples/";
      </script>
<script defer="" src="../js/jquery-3.6.0.min.js"></script>
<!--[if lt IE 9]>
      <script src="../js/html5shiv.min.js"></script>
    <![endif]-->
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>
</head>
<body class="wy-body-for-nav" role="document">
<div class="wy-grid-for-nav">
<nav class="wy-nav-side stickynav" data-toggle="wy-nav-shift">
<div class="wy-side-scroll">
<div class="wy-side-nav-search">
<a class="icon icon-home" href=".."> Rāpoi Cluster Documentation
        </a><div role="search">
<form action="../search.html" class="wy-form" id="rtd-search-form" method="get">
<input name="q" placeholder="Search docs" title="Type search term here" type="text"/>
</form>
</div>
</div>
<div aria-label="Navigation menu" class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation">
<ul>
<li class="toctree-l1"><a class="reference internal" href="..">Overview</a>
</li>
</ul>
<p class="caption"><span class="caption-text">Documentation</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../accessing_the_cluster/">Accessing the Cluster</a>
</li>
<li class="toctree-l1"><a class="reference internal" href="../basic_commands/">Basic Commands</a>
</li>
<li class="toctree-l1"><a class="reference internal" href="../storage/">Storage and Quotas</a>
</li>
<li class="toctree-l1"><a class="reference internal" href="../partitions/">Using Partitions</a>
</li>
<li class="toctree-l1"><a class="reference internal" href="../environment/">Preparing your Environment (modules)</a>
</li>
<li class="toctree-l1"><a class="reference internal" href="../new_mod/">New module system</a>
</li>
<li class="toctree-l1"><a class="reference internal" href="../running_jobs/">Running Jobs</a>
</li>
<li class="toctree-l1"><a class="reference internal" href="../parallel_processing/">Parallel Processing</a>
</li>
<li class="toctree-l1"><a class="reference internal" href="../managing_jobs/">Managing Jobs</a>
</li>
<li class="toctree-l1"><a class="reference internal" href="../cloud_providers/">Connecting to Cloud Providers</a>
</li>
<li class="toctree-l1"><a class="reference internal" href="../containers/">Using Containers</a>
</li>
<li class="toctree-l1"><a class="reference internal" href="../notebooks/">Using Jupyter Notebooks</a>
</li>
<li class="toctree-l1 current"><a class="reference internal current" href="./">Examples</a>
<ul class="current">
<li class="toctree-l2"><a class="reference internal" href="#simple-bash-example-start-here-if-new-to-hpc">Simple Bash Example - start here if new to HPC</a>
</li>
<li class="toctree-l2"><a class="reference internal" href="#simple-python-program-using-virtualenv-and-pip">Simple Python program using virtualenv and pip</a>
</li>
<li class="toctree-l2"><a class="reference internal" href="#using-anacondaminicondaconda-idba">Using Anaconda/Miniconda/conda - idba</a>
</li>
<li class="toctree-l2"><a class="reference internal" href="#loading-r-packages-running-a-simple-job">Loading R packages &amp; running a simple job</a>
</li>
<li class="toctree-l2"><a class="reference internal" href="#matlab-gpu-example">Matlab GPU example</a>
</li>
<li class="toctree-l2"><a class="reference internal" href="#job-arrays-running-many-similar-jobs">Job Arrays - running many similar jobs</a>
<ul>
<li class="toctree-l3"><a class="reference internal" href="#simple-bash-job-array-example">Simple Bash Job Array example</a>
</li>
<li class="toctree-l3"><a class="reference internal" href="#a-simple-r-job-array-example">A simple R job Array Example</a>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#singularity">Singularity</a>
<ul>
<li class="toctree-l3"><a class="reference internal" href="#singularitydocker-container-example">Singularity/Docker container example</a>
</li>
<li class="toctree-l3"><a class="reference internal" href="#singularitytensorflow-example">Singularity/TensorFlow Example</a>
</li>
<li class="toctree-l3"><a class="reference internal" href="#singularitymaxbin2-example">Singularity/MaxBin2 Example</a>
</li>
<li class="toctree-l3"><a class="reference internal" href="#singularitysandbox-example">Singularity/Sandbox Example</a>
</li>
<li class="toctree-l3"><a class="reference internal" href="#singularitycustom-conda-container-idba-example">Singularity/Custom Conda Container - idba example</a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../training/">Training</a>
</li>
<li class="toctree-l1"><a class="reference internal" href="../usersub/">User Submitted Docs</a>
</li>
<li class="toctree-l1"><a class="reference internal" href="../faq/">FAQ</a>
</li>
<li class="toctree-l1"><a class="reference internal" href="../hpclayout/">HPC Hardware Layout</a>
</li>
<li class="toctree-l1"><a class="reference internal" href="../support/">Support</a>
</li>
</ul>
</div>
</div>
</nav>
<section class="wy-nav-content-wrap" data-toggle="wy-nav-shift">
<nav aria-label="Mobile navigation menu" class="wy-nav-top" role="navigation">
<i class="fa fa-bars" data-toggle="wy-nav-top"></i>
<a href="..">Rāpoi Cluster Documentation</a>
</nav>
<div class="wy-nav-content">
<div class="rst-content"><div aria-label="breadcrumbs navigation" role="navigation">
<ul class="wy-breadcrumbs">
<li><a alt="Docs" class="icon icon-home" href=".."></a> »</li>
<li>Documentation »</li><li>Examples</li>
<li class="wy-breadcrumbs-aside">
</li>
</ul>
<hr/>
</div>
<div class="document" itemscope="itemscope" itemtype="http://schema.org/Article" role="main">
<div class="section" itemprop="articleBody">
<h1 id="examples">Examples<a class="headerlink" href="#examples" title="Permanent link">¶</a></h1>
<h2 id="simple-bash-example-start-here-if-new-to-hpc">Simple Bash Example - start here if new to HPC<a class="headerlink" href="#simple-bash-example-start-here-if-new-to-hpc" title="Permanent link">¶</a></h2>
<p>In this example we will run a very simple bash script on the quicktest partition.  The bash script is very simple, it just prints the hostname - the node you're running on - and prints the date into a file.  It also sleeps for 1 minute - it just does this to give you a chance to see your job in the queue with <code>squeue</code></p>
<p>First lets create a sensible working directory</p>
<p><div class="highlight"><pre><span></span><code>mkdir bash_example
<span class="nb">cd</span> bash_example
</code></pre></div>
We'll use the text editor nano to create our bash script as well as our submission script.  In real life, you might find it easier to create your code and submission script on your local machine, then copy them over as nano is not a great editor for large projects.</p>
<p>Create and edit our simple bash script - this is our code we will run on the HPC
<div class="highlight"><pre><span></span><code>nano test.sh
</code></pre></div></p>
<p>Paste or type the following into the file
<div class="highlight"><pre><span></span><code><span class="ch">#!/bin/bash</span>

hostname  <span class="c1">#prints the host name to the terminal</span>
date &gt; date_when_job_ran.txt  <span class="c1">#puts the content of the date command into a txt file</span>
sleep 1m <span class="c1"># do nothing for 1 minute.  Job will still be "running" </span>
</code></pre></div>
press ctrl-O to save the text in nano, then ctrl-X to exit nano.</p>
<p>Using nano again create a file called submit.sh with the following content
<div class="highlight"><pre><span></span><code><span class="ch">#!/bin/bash</span>
<span class="c1">#</span>
<span class="c1">#SBATCH --job-name=bash_test</span>
<span class="c1">#SBATCH -o bash_test.out</span>
<span class="c1">#SBATCH -e bash_test.err</span>
<span class="c1">#</span>
<span class="c1">#SBATCH --partition=quicktest</span>
<span class="c1">#</span>
<span class="c1">#SBATCH --cpus-per-task=1</span>
<span class="c1">#SBATCH --mem=1G</span>
<span class="c1">#SBATCH --time=10:00</span>

bash test.sh  <span class="c1">#actually run our bash script, using bash</span>
</code></pre></div></p>
<p>If you're familiar with bash scripts, the above is a bit weird.  The <code>#SBATCH</code> lines would normally be comments and hence not do anything, but Slurm will read those lines to determine how many resources to provide your job.  In this case we ask for the following:</p>
<ul>
<li>quicktest partition (the default - so you don't technically need to ask for it). </li>
<li>1 cpu per task - we have one task, so we're asking for 1 cpu</li>
<li>1 gig of memory.</li>
<li>a max runtime of 10 min</li>
</ul>
<p>If your job uses more memory or time than requested, Slurm will immediately kill it.  If you use more CPU's than requested - your job will keep running, but your "cpus" will be shared bewteen the CPUs you actually requested. So if your job tried to use 10 CPUs but you only asked for one, it'll run extremely slowly - don't do this.</p>
<p>Our <code>submit.sh</code> script also names our job <code>bash_test</code> this is what the job will show up as in squeue. We ask for things printed out on the terminal to go to two seperate files.  Normal, non error, things that would be printed out on the terminal will be put into the text file <code>bash_test.out</code>.  Errors will be printed into the text file <code>bash_test.err</code></p>
<p>Now submit your job to the Slurm queue.
<div class="highlight"><pre><span></span><code>sbatch submit.sh  

<span class="c1">#See your job in the queue</span>
squeue -u &lt;your_username&gt;

<span class="c1">#When job is done see the new files</span>
ls

<span class="c1">#look at the content that would have been printed to the terminal if running locally</span>
cat bash_test.out

<span class="c1"># See the content of the file that your bash script created</span>
cat date_when_job_ran.txt
</code></pre></div></p>
<h2 id="simple-python-program-using-virtualenv-and-pip">Simple Python program using virtualenv and pip<a class="headerlink" href="#simple-python-program-using-virtualenv-and-pip" title="Permanent link">¶</a></h2>
<p>First we need to create a working directory and move there
<div class="highlight"><pre><span></span><code>mkdir python_test
<span class="nb">cd</span> python_test
</code></pre></div>
Next we load the python 3 module and use python 3 to create a python virtualenv.  This way we can install pip packages which are not installed on the cluster
<div class="highlight"><pre><span></span><code>module load python/3.6.6
python3 -m venv mytest
</code></pre></div></p>
<p>Activate the <code>mytest</code> virtualenv and use pip to install the <code>webcolors</code> package
<div class="highlight"><pre><span></span><code><span class="nb">source</span> mytest/bin/activate
pip install webcolors
</code></pre></div></p>
<p>Create the file test.py with the following contents using nano
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">webcolors</span>
<span class="kn">from</span> <span class="nn">random</span> <span class="kn">import</span> <span class="n">randint</span>
<span class="kn">from</span> <span class="nn">socket</span> <span class="kn">import</span> <span class="n">gethostname</span>

<span class="n">colour_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">webcolors</span><span class="o">.</span><span class="n">CSS3_HEX_TO_NAMES</span><span class="o">.</span><span class="n">items</span><span class="p">())</span>
<span class="n">requested_colour</span> <span class="o">=</span> <span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">colour_list</span><span class="p">))</span>
<span class="n">colour_name</span> <span class="o">=</span> <span class="n">colour_list</span><span class="p">[</span><span class="n">requested_colour</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"Random colour name:"</span><span class="p">,</span> <span class="n">colour_name</span><span class="p">,</span> <span class="s2">" on host: "</span><span class="p">,</span> <span class="n">gethostname</span><span class="p">())</span>
</code></pre></div></p>
<p>Alternatively download it with wget:
<div class="highlight"><pre><span></span><code>wget https://raw.githubusercontent.com/<span class="se">\</span>
    vuw-research-computing/raapoi-tools/<span class="se">\</span>
    master/examples/python_venv/test.py
</code></pre></div></p>
<p>Using nano create the submissions script called python_submit.sh with the following content - change <code>me@email.com</code> to your email address.
<div class="highlight"><pre><span></span><code><span class="ch">#!/bin/bash</span>
<span class="c1">#</span>
<span class="c1">#SBATCH --job-name=python_test</span>
<span class="c1">#SBATCH -o python_test.out</span>
<span class="c1">#SBATCH -e python_test.err</span>
<span class="c1">#</span>
<span class="c1">#SBATCH --cpus-per-task=1</span>
<span class="c1">#SBATCH --mem-per-cpu=1G</span>
<span class="c1">#SBATCH --time=10:00</span>
<span class="c1">#</span>
<span class="c1">#SBATCH --mail-type=BEGIN,END,FAIL</span>
<span class="c1">#SBATCH --mail-user=me@email.com</span>

module load python/3.6.6

<span class="nb">source</span> mytest/bin/activate
python test.py
</code></pre></div></p>
<p>Alternatively download it with wget
<div class="highlight"><pre><span></span><code>wget https://raw.githubusercontent.com/<span class="se">\</span>
    vuw-research-computing/raapoi-tools/<span class="se">\</span>
    master/examples/python_venv/python_submit.sh
</code></pre></div></p>
<p>To submit your job to the Slurm scheduler
<div class="highlight"><pre><span></span><code>sbatch python_submit.sh
</code></pre></div></p>
<p>Check for your job on the queue with <code>squeue</code> though it might finish very fast.  The output files will appear in your working directory.</p>
<!-- BEGIN INCLUDE examples/anaconda.md   -->
<h2 id="using-anacondaminicondaconda-idba">Using Anaconda/Miniconda/conda - idba<a class="headerlink" href="#using-anacondaminicondaconda-idba" title="Permanent link">¶</a></h2>
<p>Many users use Anaconda/Miniconda to manage software stacks.  One way to do this is to use singularity containers with the conda environment inside - this allows the conda environment to load quickly as the many small conda files are inside a container which the file system sees as one file.</p>
<p>However, this is also an additional bit of complexity so many users just use conda outside of singularity.  You can install your own version of Anaconda/Miniconda to your home directory or scratch.  We have also got packaged versions of Anaconda/Miniconda installed with our module loading system.</p>
<p>Anaconda has many built in packages so we will use that in our examples, but Miniconda is available if you want a more minimal initial setup.</p>
<div class="highlight"><pre><span></span><code>module load old-mod-system/Anaconda3/2020.11 
</code></pre></div>
<p>Let's create a new conda environment for this example, in a sensible location, I used <code>~/examples/conda/idba</code></p>
<div class="highlight"><pre><span></span><code>conda create --name idba-example  <span class="c1"># press y for the Proceed prompt if it looks correct</span>
conda activate idba-example  <span class="c1">#activate our example environment.</span>
</code></pre></div>
<p>Conda environments are beyond the scope of this example, but they are a good way to contain all the dependencies and programs for a particular workflow, in this case, idba.</p>
<p>Install idba in our conda environment.</p>
<div class="highlight"><pre><span></span><code>conda install -c bioconda idba
</code></pre></div>
<p>Idba is a genome assembler, we will use paired-end illumina reads of E. coli.  The data is available on an Amazon S3 bucket (a cloud storage location), and we can download it using wget.
<div class="highlight"><pre><span></span><code>mkdir data  <span class="c1"># put our data in a sensible location</span>
<span class="nb">cd</span> data
wget --content-disposition goo.gl/JDJTaz <span class="c1">#sequence data</span>
wget --content-disposition goo.gl/tt9fsn <span class="c1">#sequence data</span>
<span class="nb">cd</span> ..  <span class="c1">#back to our project directory</span>
</code></pre></div></p>
<p>The reads we have are paired-end fastq files but idba requires a fasta file. We can use a tool installed with idba to convert them. We'll do this on the Rāpoi login node as it is a fast task that doesn't need many resources.</p>
<div class="highlight"><pre><span></span><code>fq2fa --merge --filter data/MiSeq_Ecoli_MG1655_50x_R1.fastq data/MiSeq_Ecoli_MG1655_50x_R2.fastq data/read.fa
</code></pre></div>
<p>To create our submission script we need to know the path to our conda enviroment. To get this:
<div class="highlight"><pre><span></span><code>conda env list
</code></pre></div>
You'll need to find your <code>idba-example</code> environment, and next to it is the path you'll need for your submission script.  In my case:
<div class="highlight"><pre><span></span><code><span class="c1"># conda environments:</span>
<span class="c1">#</span>
base                  *  /home/andre/anaconda3
idba-example          /home/andre/anaconda3/envs/idba-example  <span class="c1"># We need this line, it'll be different for you!</span>
</code></pre></div></p>
<p>Create our sbatch submission script. Note that this sequence doesn't need a lot of memory, so we'll use 3G. To see your usage after the job has run use <code>vuw-job-report &lt;job-id&gt;</code></p>
<p><em>idba_submit.sh</em>
<div class="highlight"><pre><span></span><code><span class="ch">#!/bin/bash</span>

<span class="c1">#SBATCH --job-name=idba_test</span>
<span class="c1">#SBATCH -o _output.out</span>
<span class="c1">#SBATCH -e _output.err</span>
<span class="c1">#SBATCH --time=00:5:00</span>
<span class="c1">#SBATCH --partition=quicktest</span>
<span class="c1">#SBATCH --ntasks=12</span>
<span class="c1">#SBATCH --mem=3G</span>

module load old-mod-system/Anaconda3/2020.11
<span class="nb">eval</span> <span class="s2">"</span><span class="k">$(</span>conda shell.bash hook<span class="k">)</span><span class="s2">"</span> <span class="c1"># basically inits your conda - prevents errors like: CommandNotFoundError: Your shell has not been properly configured ...</span>
conda activate /home/andre/anaconda3/envs/idba-example  <span class="c1"># We will need to activate our conda enviroment on the remote node</span>
idba idba_ud -r data/read.fa -o output
</code></pre></div></p>
<p>To submit our job
<div class="highlight"><pre><span></span><code>sbatch idba_submit.sh
</code></pre></div></p>
<p>To see our job running or queuing
<div class="highlight"><pre><span></span><code>squeue -u <span class="nv">$USER</span>
</code></pre></div>
This job will take a few minutes to run, generally less than 5.
When the job is done we can see the output in the output folder.  We can also see the std output and std err in the files <code>_output.out and _output.err</code>.  The quickest way to examine them is to <code>cat</code> the files when the run is done.
<div class="highlight"><pre><span></span><code>cat _output.out
</code></pre></div></p>
<!-- END INCLUDE -->
<h2 id="loading-r-packages-running-a-simple-job">Loading R packages &amp; running a simple job<a class="headerlink" href="#loading-r-packages-running-a-simple-job" title="Permanent link">¶</a></h2>
<p>First login to Rāpoi and load the R and R/CRAN modules:
<div class="highlight"><pre><span></span><code>module load R/4.0.2
module load R/CRAN      
</code></pre></div></p>
<p>Then run R on the command line:</p>
<div class="highlight"><pre><span></span><code>R
</code></pre></div>
<p>Test library existence:
<div class="highlight"><pre><span></span><code><span class="o">&gt;</span> <span class="nf">library</span><span class="p">(</span><span class="n">tidyverse</span><span class="p">)</span>
</code></pre></div>
This should load the package, and give some output like this:</p>
<p><div class="highlight"><pre><span></span><code>── <span class="n">Attaching</span> <span class="n">packages</span> ─────────────────────────────────────── <span class="n">tidyverse</span> <span class="m">1.3</span><span class="n">.</span><span class="m">0</span> ──
✔ <span class="n">ggplot2</span> <span class="m">3.3</span><span class="n">.</span><span class="m">2</span>     ✔ <span class="n">purrr</span>   <span class="m">0.3</span><span class="n">.</span><span class="m">4</span>
✔ <span class="n">tibble</span>  <span class="m">3.0</span><span class="n">.</span><span class="m">1</span>     ✔ <span class="n">dplyr</span>   <span class="m">1.0</span><span class="n">.</span><span class="m">0</span>
✔ <span class="n">tidyr</span>   <span class="m">1.1</span><span class="n">.</span><span class="m">0</span>     ✔ <span class="n">stringr</span> <span class="m">1.4</span><span class="n">.</span><span class="m">0</span>
✔ <span class="n">readr</span>   <span class="m">1.3</span><span class="n">.</span><span class="m">1</span>     ✔ <span class="n">forcats</span> <span class="m">0.5</span><span class="n">.</span><span class="m">0</span>
── <span class="n">Conflicts</span> ────────────────────────────────────────── <span class="nf">tidyverse_conflicts</span><span class="p">()</span> ──
✖ <span class="n">dplyr</span><span class="o">::</span><span class="nf">filter</span><span class="p">()</span> <span class="n">masks</span> <span class="n">stats</span><span class="o">::</span><span class="nf">filter</span><span class="p">()</span>
✖ <span class="n">dplyr</span><span class="o">::</span><span class="nf">lag</span><span class="p">()</span>    <span class="n">masks</span> <span class="n">stats</span><span class="o">::</span><span class="nf">lag</span><span class="p">()</span>
</code></pre></div>
(These conflicts are normal and can be ignored.)</p>
<p>To quit R, type:</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;</span> <span class="nf">q</span><span class="p">()</span>
</code></pre></div>
<p>Next create a bash submission script called <code>r_submit.sh</code> (or another name of your choice) using your preferred text editor, e.g. nano.</p>
<div class="highlight"><pre><span></span><code><span class="ch">#!/bin/bash</span>
<span class="c1">#</span>
<span class="c1">#SBATCH --job-name=r_test</span>
<span class="c1">#SBATCH -o r_test.out</span>
<span class="c1">#SBATCH -e r_test.err</span>
<span class="c1">#</span>
<span class="c1">#SBATCH --cpus-per-task=1</span>
<span class="c1">#SBATCH --mem-per-cpu=1G</span>
<span class="c1">#SBATCH --time=10:00</span>
<span class="c1">#</span>

module load R/4.0.2
module load R/CRAN

Rscript mytest.R
</code></pre></div>
<p>Save this to the current working directory, and then create another file using your preferred text editor called <code>mytest.R</code> (or another name of your choice) containing the following R commands:</p>
<p><div class="highlight"><pre><span></span><code><span class="nf">library</span><span class="p">(</span><span class="n">tidyverse</span><span class="p">)</span>

<span class="nf">sprintf</span><span class="p">(</span><span class="s">"Hello World!"</span><span class="p">)</span>
</code></pre></div>
then run it with the previously written bash script:<br/>
<div class="highlight"><pre><span></span><code>sbatch r_submit.sh 
</code></pre></div>
This submits a task that should execute quickly and create files in the directory from which it was run.
Examine <code>r_test.out</code>. You can use an editor like nano, vi or emacs, or you can just <code>cat</code> or <code>less</code> the file to see its contents on the terminal. You should see:
<code>"Hello World"</code></p>
<h2 id="matlab-gpu-example">Matlab GPU example<a class="headerlink" href="#matlab-gpu-example" title="Permanent link">¶</a></h2>
<p>Matlab has various built-in routines which are GPU accelerated.  We will run a simple speed comparison between cpu and gpu tasks. In a sensible location create a file called <code>matlab_gpu.m</code>  I used <code>~/examples/matlab/cuda/matlab_gpu.m</code>.</p>
<div class="highlight"><pre><span></span><code><span class="c">% Set an array which will calculate the Eigenvalues of</span><span class="w"></span>
<span class="n">A</span><span class="p">=</span><span class="nb">rand</span><span class="p">(</span><span class="mi">1000</span><span class="p">);</span><span class="w"></span>

<span class="c">% Copy the Array to the GPU memory - this process takes an erratic amount of time, so we will not time it.</span><span class="w"></span>
<span class="n">Agpu</span><span class="p">=</span><span class="n">gpuArray</span><span class="p">(</span><span class="n">A</span><span class="p">);</span><span class="w"></span>
<span class="n">tic</span><span class="w"></span>
<span class="s">B=eig(Agpu)</span><span class="p">;</span><span class="w"></span>
<span class="n">t1</span><span class="p">=</span><span class="nb">toc</span><span class="w"></span>

<span class="c">% Let's compare the time with CPU</span><span class="w"></span>
<span class="nb">tic</span><span class="w"></span>
<span class="n">B</span><span class="p">=</span><span class="nb">eig</span><span class="p">(</span><span class="n">A</span><span class="p">);</span><span class="w"></span>
<span class="n">t2</span><span class="p">=</span><span class="nb">toc</span><span class="w"></span>
</code></pre></div>
<p>We will also need a Slurm submission script; we'll call this <code>matlab_gpu.sh</code>. Note that we will need to use the new Easybuild module files for our cuda libraries, so make sure to include the module use line <code>module use /home/software/tools/eb_modulefiles/all/Core</code></p>
<div class="highlight"><pre><span></span><code><span class="ch">#!/bin/bash</span>

<span class="c1">#SBATCH --job-name=matlab-gpu-example</span>
<span class="c1">#SBATCH --output=out-gpu-example.out</span>
<span class="c1">#SBATCH --error=out-gpu-example.err</span>
<span class="c1">#SBATCH --time=00:05:00</span>
<span class="c1">#SBATCH --partition=gpu</span>
<span class="c1">#SBATCH --gres=gpu:1</span>
<span class="c1">#SBATCH --ntasks=2</span>
<span class="c1">#SBATCH --mem=60G</span>

module use /home/software/tools/eb_modulefiles/all/Core
module load matlab/2021a
module load fosscuda/2020b

matlab -nodisplay -nosplash -nodesktop -r <span class="s2">"run('matlab_gpu.m');exit;"</span>
</code></pre></div>
<p>To submit this job to the Slurm queue <code>sbatch matlab_gpu.sh</code>.  This job will take a few minutes to run - this is mostly the Matlab startup time.
Examine the queue for your job <code>squeue -u $USER</code>.  When your job is done, inspect the output file.  You can use an editor like nano, vi or emacs, or you can just <code>cat</code> or <code>less</code> the file to see its contents on the terminal.</p>
<p><div class="highlight"><pre><span></span><code>cat out-gpu-example.out
</code></pre></div>
What do you notice about the output?  Surely GPUs should be faster than the CPU!  It takes time for the GPU to start processing your task, the CPU is able to start the task far more quickly.  So for short operations, the CPU can be faster than the GPU - remember to benchmark your code for optimal performance!  Just because you can use a GPU for your task doesn't mean it is necessarily faster!</p>
<p>To get a better idea of the advantage of the GPU let's increase the size of the array from <code>1000</code> to <code>10000</code></p>
<p><em>matlab_gpu.m</em>
<div class="highlight"><pre><span></span><code><span class="c">% Set an array which will calculate the Eigenvalues of</span><span class="w"></span>
<span class="n">A</span><span class="p">=</span><span class="nb">rand</span><span class="p">(</span><span class="mi">10000</span><span class="p">);</span><span class="w"></span>

<span class="c">% Copy the Array to the GPU memory - this process takes an erratic amount of time, so we will not time it.</span><span class="w"></span>
<span class="n">Agpu</span><span class="p">=</span><span class="n">gpuArray</span><span class="p">(</span><span class="n">A</span><span class="p">);</span><span class="w"></span>
<span class="n">tic</span><span class="w"></span>
<span class="s">B=eig(Agpu)</span><span class="p">;</span><span class="w"></span>
<span class="n">t1</span><span class="p">=</span><span class="nb">toc</span><span class="w"></span>

<span class="c">% Let's compare the time with CPU</span><span class="w"></span>
<span class="nb">tic</span><span class="w"></span>
<span class="n">B</span><span class="p">=</span><span class="nb">eig</span><span class="p">(</span><span class="n">A</span><span class="p">);</span><span class="w"></span>
<span class="n">t2</span><span class="p">=</span><span class="nb">toc</span><span class="w"></span>
</code></pre></div></p>
<p>To make things fairer for the CPU in this case, we will also allocate half the CPUs on the node to Matlab.  Half the CPUs, half the memory and half the GPUs, just to be fair.</p>
<p><em>matlab_gpu.sh</em>
<div class="highlight"><pre><span></span><code>#!/bin/bash

#SBATCH --job-name=matlab-gpu-example
#SBATCH --output=out-gpu-example.out
#SBATCH --error=out-gpu-example.err
#SBATCH --time=00:05:00
#SBATCH --partition=gpu
#SBATCH --gres=gpu:1
#SBATCH --ntasks=128
#SBATCH --mem=256G

module use /home/software/tools/eb_modulefiles/all/Core
module load matlab/2021a
module load fosscuda/2020b

matlab -nodisplay -nosplash -nodesktop -r "run('matlab_gpu.m');exit;"
</code></pre></div></p>
<p>The output in my case was:
<div class="highlight"><pre><span></span><code>                            &lt; M A T L A B <span class="o">(</span>R<span class="o">)</span> &gt;
                  Copyright <span class="m">1984</span>-2021 The MathWorks, Inc.
             R2021a Update <span class="m">1</span> <span class="o">(</span><span class="m">9</span>.10.0.1649659<span class="o">)</span> <span class="m">64</span>-bit <span class="o">(</span>glnxa64<span class="o">)</span>
                               April <span class="m">13</span>, <span class="m">2021</span>


To get started, <span class="nb">type</span> doc.
For product information, visit www.mathworks.com.


<span class="nv">t1</span> <span class="o">=</span>

   <span class="m">62</span>.0212


<span class="nv">t2</span> <span class="o">=</span>

  <span class="m">223</span>.0818
</code></pre></div></p>
<p>So in thise case the GPU was considerably faster.  Matlab can do this a bit faster on the CPU if you give it <strong>fewer</strong> CPUs, the optimum appears to be around 20, but it still takes 177s.  Again, optimise your resource requests for your problem, less can sometimes be more, however the GPU easily wins  in this case.</p>
<h2 id="job-arrays-running-many-similar-jobs">Job Arrays - running many similar jobs<a class="headerlink" href="#job-arrays-running-many-similar-jobs" title="Permanent link">¶</a></h2>
<p>Slurm makes it easy to run many jobs which are similar to each other.  This could be one piece of code running over many datasets in parallel or running a set of simulations with a different set of parameters for each run.</p>
<h3 id="simple-bash-job-array-example">Simple Bash Job Array example<a class="headerlink" href="#simple-bash-job-array-example" title="Permanent link">¶</a></h3>
<p>The following code will run the submission script 16 times as resources become available (i.e. they will not neccesarily run at the same time).  It will just print out the Slurm array task ID and exit.</p>
<p><em>submit.sh:</em>
<div class="highlight"><pre><span></span><code><span class="ch">#!/bin/bash</span>

<span class="c1">#SBATCH --job-name=test_array</span>
<span class="c1">#SBATCH --output=out_array_%A_%a.out</span>
<span class="c1">#SBATCH --error=out_array_%A_%a.err</span>
<span class="c1">#SBATCH --array=1-16</span>
<span class="c1">#SBATCH --time=00:00:20</span>
<span class="c1">#SBATCH --partition=parallel</span>
<span class="c1">#SBATCH --ntasks=1</span>
<span class="c1">#SBATCH --mem=1G</span>

<span class="c1"># Print the task id.</span>
<span class="nb">echo</span> <span class="s2">"My SLURM_ARRAY_TASK_ID: "</span> <span class="nv">$SLURM_ARRAY_TASK_ID</span>

<span class="c1"># Add lines here to run your computations.</span>
</code></pre></div></p>
<p>Run the example with the standard
<div class="highlight"><pre><span></span><code>sbatch submit.sh
</code></pre></div></p>
<h3 id="a-simple-r-job-array-example">A simple R job Array Example<a class="headerlink" href="#a-simple-r-job-array-example" title="Permanent link">¶</a></h3>
<p>As a slightly more practical example the following will run an R script 5 times as resources become available.  The R script takes as an input the <code>$SLURM_ARRAY_TASK_ID</code> which then selects a parameter <code>alpha</code> out of a lookup table.</p>
<p>This is one way you could run simulations or similar with a set parameters defined in a lookuop table in your code.</p>
<p>To make outputs more tidy and to help organisation, instead of dumping all the outputs into the directory with our code and submission script, we will separate the outputs into directories.  Dataframes saved from R will be saved to the output/ directory, and all output which would otherwise be printed to the commnd line (stdout and stderr) will be saved to the stdout/ directory. Both of these directories will need to be created before running the script.</p>
<p><em>r_random_alpha.R:</em>
<div class="highlight"><pre><span></span><code><span class="c1"># get the arguments supplied to R.  </span>
<span class="c1"># trailingOnly = TRUE gets the user supplied</span>
<span class="c1"># arguments, and for now we will only get the</span>
<span class="c1"># first user supplied argument</span>
<span class="n">args</span> <span class="o">&lt;-</span> <span class="nf">commandArgs</span><span class="p">(</span><span class="n">trailingOnly</span> <span class="o">=</span> <span class="kc">TRUE</span><span class="p">)</span>
<span class="n">inputparam</span> <span class="o">&lt;-</span> <span class="n">args</span><span class="p">[</span><span class="m">1</span><span class="p">]</span>

<span class="c1"># a vector with all our parameters.</span>
<span class="n">alpha_vec</span> <span class="o">&lt;-</span> <span class="nf">c</span><span class="p">(</span><span class="m">2.5</span><span class="p">,</span> <span class="m">3.3</span><span class="p">,</span> <span class="m">5.1</span><span class="p">,</span> <span class="m">8.2</span><span class="p">,</span> <span class="m">10.9</span><span class="p">)</span>
<span class="n">alpha</span> <span class="o">&lt;-</span> <span class="n">alpha_vec</span><span class="p">[</span><span class="nf">as.integer</span><span class="p">(</span><span class="n">inputparam</span><span class="p">)]</span>

<span class="c1"># Generate a random number between 0 and alpha </span>
<span class="c1"># store it in dataframe with the coresponding </span>
<span class="c1"># alpha value</span>
<span class="n">randomnum</span> <span class="o">&lt;-</span> <span class="nf">runif</span><span class="p">(</span><span class="m">1</span><span class="p">,</span> <span class="n">min</span><span class="o">=</span><span class="m">0</span><span class="p">,</span> <span class="n">max</span><span class="o">=</span><span class="nf">as.double</span><span class="p">(</span><span class="n">alpha</span><span class="p">))</span>
<span class="n">df</span> <span class="o">&lt;-</span> <span class="nf">data.frame</span><span class="p">(</span><span class="s">"alpha"</span> <span class="o">=</span> <span class="n">alpha</span><span class="p">,</span> <span class="s">"random_num"</span> <span class="o">=</span> <span class="n">randomnum</span><span class="p">)</span>

<span class="c1"># Save the data frame to a file with the alpha value</span>
<span class="c1"># Note that the output/ folder will need to be </span>
<span class="c1"># manually created first!</span>
<span class="n">outputname</span> <span class="o">&lt;-</span> <span class="nf">paste</span><span class="p">(</span><span class="s">"output/"</span><span class="p">,</span> <span class="s">"alpha_"</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="s">".Rda"</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s">""</span><span class="p">)</span>
<span class="nf">save</span><span class="p">(</span><span class="n">df</span><span class="p">,</span><span class="n">file</span><span class="o">=</span><span class="n">outputname</span><span class="p">)</span>
</code></pre></div></p>
<p>Next create the submision script. Which we will run on the parallel partition rather than quicktest.</p>
<p>r_submit.sh:
<div class="highlight"><pre><span></span><code><span class="ch">#!/bin/bash</span>
<span class="c1">#SBATCH --job-name=test_R_array</span>
<span class="c1">#SBATCH --output=stdout/array_%A_%a.out</span>
<span class="c1">#SBATCH --error=stdout/array_%A_%a.err</span>
<span class="c1">#SBATCH --array=1-5</span>
<span class="c1">#SBATCH --time=00:00:20</span>
<span class="c1">#SBATCH --partition=parallel</span>
<span class="c1">#SBATCH --ntasks=1</span>
<span class="c1">#SBATCH --mem=1G</span>

module load R/CRAN

<span class="c1"># Print the task id.</span>
Rscript r_random_alpha.R <span class="nv">$SLURM_ARRAY_TASK_ID</span>
</code></pre></div></p>
<p>Run the jobs with
<div class="highlight"><pre><span></span><code>sbatch r_submit.sh
</code></pre></div></p>
<h2 id="singularity">Singularity<a class="headerlink" href="#singularity" title="Permanent link">¶</a></h2>
<p>While there are many modules on Rāpoi, sometimes you might want to install your own packages in your own way.  Singularity allows you to do this.  If you are familiar with Docker, Singularity is similar, except you can't get root (or sudo) once your container is running on the Rāpoi.  However, you <em>can</em> have sudo rights locally on your own machine, setup your container however you like, then run it without sudo on the cluster.</p>
<h3 id="singularitydocker-container-example">Singularity/Docker container example<a class="headerlink" href="#singularitydocker-container-example" title="Permanent link">¶</a></h3>
<p>Singularity allows you to use most (but not all!) docker images on Rāpoi.</p>
<p>On your local machine create the singularity definition file</p>
<p>input_args_example.def
<div class="highlight"><pre><span></span><code><span class="k">BootStrap</span>:<span class="w"> </span>library
<span class="k">From</span>:<span class="w"> </span>ubuntu:<span class="m">16.04</span>

<span class="gh">%runscript</span><span class="w"></span>
<span class="w">    </span><span class="nb">exec</span> <span class="nb">echo</span> <span class="s2">"</span><span class="nv">$@</span><span class="s2">"</span>

<span class="gh">%labels</span><span class="w"></span>
<span class="w">    </span>Author Andre
</code></pre></div></p>
<p>This will build an ubuntu 16.04 container that will eventually run on Rāpoi which runs Centos.  This container has a runscript which just echos back any arguments sent to the container when your start it up.</p>
<p>Build the container <em>locally</em> with sudo and singularity
<div class="highlight"><pre><span></span><code>sudo singularity build inputexample.sif input_args_example.def 
</code></pre></div></p>
<p>This will build an image that you can't modify any further and is immediately suitable to run on Rāpoi
Copy this file to Rāpoi via sftp
<div class="highlight"><pre><span></span><code>sftp &lt;username&gt;@raapoi.vuw.ac.nz
</code></pre></div></p>
<p>Create a submit script using singularity on the cluster</p>
<p>singularity_submit.sh
<div class="highlight"><pre><span></span><code><span class="ch">#!/bin/bash</span>

<span class="c1">#SBATCH --job-name=singularity_test</span>
<span class="c1">#SBATCH -o sing_test.out</span>
<span class="c1">#SBATCH -e sing_test.err</span>
<span class="c1">#SBATCH --time=00:00:20</span>
<span class="c1">#SBATCH --ntasks=1</span>
<span class="c1">#SBATCH --mem=1G</span>

module load singularity

singularity run inputtest.sif <span class="s2">"hello from a container"</span>
</code></pre></div></p>
<p>Run the script with the usual
<div class="highlight"><pre><span></span><code>singularity_submit.sh
</code></pre></div></p>
<h3 id="singularitytensorflow-example">Singularity/TensorFlow Example<a class="headerlink" href="#singularitytensorflow-example" title="Permanent link">¶</a></h3>
<p>tensor.def
<div class="highlight"><pre><span></span><code>Bootstrap: docker
From: tensorflow/tensorflow:latest-py3

%post
apt-get update <span class="o">&amp;&amp;</span> apt-get -y install wget build-essential 

%runscript
    <span class="nb">exec</span> python <span class="s2">"</span><span class="nv">$@</span><span class="s2">"</span>
</code></pre></div></p>
<p>compile this <em>locally</em> with sudo and singularity.
<div class="highlight"><pre><span></span><code>sudo singularity build tensorflow.sif tensor.def 
</code></pre></div></p>
<p>Create a quick tensorflow test code
tensortest.py
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="n">mnist</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">mnist</span>

<span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">mnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
<span class="n">x_train</span><span class="p">,</span> <span class="n">x_test</span> <span class="o">=</span> <span class="n">x_train</span> <span class="o">/</span> <span class="mf">255.0</span><span class="p">,</span> <span class="n">x_test</span> <span class="o">/</span> <span class="mf">255.0</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
  <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)),</span>
  <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">),</span>
  <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">),</span>
  <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">)</span>
<span class="p">])</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s1">'adam'</span><span class="p">,</span>
              <span class="n">loss</span><span class="o">=</span><span class="s1">'sparse_categorical_crossentropy'</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">'accuracy'</span><span class="p">])</span>

<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</code></pre></div></p>
<p>Copy your files to Rāpoi via sftp (or whatever you prefer)
<div class="highlight"><pre><span></span><code>sftp &lt;username&gt;@raapoi.vuw.ac.nz
<span class="nb">cd</span> &lt;where you want to work&gt;
put *   <span class="c1">#put all files in your local directory onto Rāpoi</span>
</code></pre></div></p>
<p>Lets quickly test the code via an interactive session on a node.  Note I find the tensorflow container only runs properly on intel nodes, which we don't have many of at the moment, I'll investigate this further.
<div class="highlight"><pre><span></span><code>srun --partition<span class="o">=</span><span class="s2">"parallel"</span> --constraint<span class="o">=</span><span class="s2">"Intel"</span> --pty bash

<span class="c1">#now on the remote node - note you might need to wait if nodes are busy</span>
module load singularity <span class="c1">#load singularity</span>
singularity shell tensorflow.sif 

<span class="c1">#now inside the tensorflow container on the remote node</span>
python tensortest.py 

<span class="c1">#once that runs, exit the container</span>
<span class="nb">exit</span> <span class="c1">#exit the container</span>
<span class="nb">exit</span> <span class="c1">#exit the interactive session on the node</span>
</code></pre></div></p>
<p>Create a submit script using singularity on the cluster</p>
<p>singularity_submit.sh
<div class="highlight"><pre><span></span><code><span class="ch">#!/bin/bash</span>

<span class="c1">#SBATCH --job-name=singularity_test</span>
<span class="c1">#SBATCH -o sing_test.out</span>
<span class="c1">#SBATCH -e sing_test.err</span>
<span class="c1">#SBATCH --time=00:10:00</span>
<span class="c1">#SBATCH --partition=parallel</span>
<span class="c1">#SBATCH --constraint=Intel</span>
<span class="c1">#SBATCH --ntasks=1</span>
<span class="c1">#SBATCH --mem=4G</span>

module load singularity

<span class="c1">#run the container with the runscript defined when we created it</span>
singularity run tensorflow.sif tensortest.py 
</code></pre></div></p>
<h3 id="singularitymaxbin2-example">Singularity/MaxBin2 Example<a class="headerlink" href="#singularitymaxbin2-example" title="Permanent link">¶</a></h3>
<p>In a sensible location, either in your home directory or on the scratch:</p>
<p>Get the maxbin2 container, there are a few places to get this, but will get the bioconda container as it is more recent than the one referenced on the official maxbin site.</p>
<div class="highlight"><pre><span></span><code>module load module load singularity
singularity pull docker://quay.io/biocontainers/maxbin2:2.2.6--h14c3975_0
mv maxbin2_2.2.6--h14c3975_0.sif maxbin2_2.2.6.sif <span class="c1">#rename for convenience</span>
</code></pre></div>
<p>Download some test data</p>
<div class="highlight"><pre><span></span><code>mkdir rawdata
curl https://downloads.jbei.org/data/microbial_communities/MaxBin/getfile.php?20x.scaffold &gt; rawdata/20x.scaffold
curl https://downloads.jbei.org/data/microbial_communities/MaxBin/getfile.php?20x.abund &gt; rawdata/20x.abund
</code></pre></div>
<p>Create an output data location
<div class="highlight"><pre><span></span><code>mkdir output
</code></pre></div></p>
<p>Create a submit script using singularity on the cluster</p>
<p>singularity_submit.sh
<div class="highlight"><pre><span></span><code><span class="ch">#!/bin/bash</span>

<span class="c1">#SBATCH --job-name=maxbin2_test</span>
<span class="c1">#SBATCH -o sing_test.out</span>
<span class="c1">#SBATCH -e sing_test.err</span>
<span class="c1">#SBATCH --time=00:10:00</span>
<span class="c1">#SBATCH --partition=parallel</span>
<span class="c1">#SBATCH --ntasks=4</span>
<span class="c1">#SBATCH --mem=4G</span>

module load singularity

singularity <span class="nb">exec</span> maxbin2_2.2.6.sif run_MaxBin.pl -contig rawdata/20x.scaffold -abund rawdata/20x.abund -out output/20x.out -thread <span class="m">4</span> 
</code></pre></div></p>
<h3 id="singularitysandbox-example">Singularity/Sandbox Example<a class="headerlink" href="#singularitysandbox-example" title="Permanent link">¶</a></h3>
<p>This lets you have root inside a container <em>locally</em> and make changes to it.  This is really handy for determining how to setuop your container.  While you can convert the sandbox container to one you can run on Rāpoi, I suggest you <em>don't do this</em>. Use the sandbox to figure out how you need to configure your container, what packages to install, config files to change etc. Then create a <code>.def</code> file that contains all the nessesary steps without the need to use the sandbox - this will make your work more reproducable and easier to share with others.</p>
<p>example.def
<div class="highlight"><pre><span></span><code>BootStrap: library
From: ubuntu:16.04

%post
apt-get update <span class="o">&amp;&amp;</span> apt-get -y install wget build-essential 

%runscript
    <span class="nb">exec</span> <span class="nb">echo</span> <span class="s2">"</span><span class="nv">$@</span><span class="s2">"</span>

%labels
    Author Andre
</code></pre></div></p>
<p>Compile this <em>locally</em> with sudo and singularity.  We are using the sandbox flag to create a writable <em>container directory</em> (<code>example/</code>) on our local machine where we have sudo rights.
<div class="highlight"><pre><span></span><code>sudo singularity build --sandbox example/ example.def
</code></pre></div></p>
<p>Now we can run the container we just built, but with sudo rights inside the container.  Your rights outside the container match the rights inside the container, so we need to do this with sudo.</p>
<div class="highlight"><pre><span></span><code>sudo singularity shell --writable example/
</code></pre></div>
<p>Inside the container we now have root and can install packages and modify files in the root directories
<div class="highlight"><pre><span></span><code>Singularity example:~&gt;  apt update
Singularity example:~&gt;  apt install sqlite
Singularity example:~&gt;  touch /test.txt  <span class="c1">#create an empty file in root</span>
Singularity example:~&gt;  ls /
Singularity example:~&gt;  <span class="nb">exit</span>   <span class="c1">#exit container</span>
</code></pre></div></p>
<p>To run the container on Rāpoi we convert it to the default immutable image with build.  We might need sudo for this as the prior use of sudo will have created a directory that your usual user can't see every file.</p>
<p><div class="highlight"><pre><span></span><code>sudo singularity build new-example-sif example/
</code></pre></div>
You could now copy the <code>new-example-sif</code> file to Rāpoi and run it there.  However a better workflow is to use this to experiment, to find out what changes you need to make to the image and what packages you need to install.  Once you've done that, I suggest starting afresh and putting <em>everything in the.def file</em>.  That way when you return to your project in 6 months, or hand it over to someone else, there is a clear record of how the image was built.</p>
<h3 id="singularitycustom-conda-container-idba-example">Singularity/Custom Conda Container - idba example<a class="headerlink" href="#singularitycustom-conda-container-idba-example" title="Permanent link">¶</a></h3>
<p>In this example we'll build a singularity container using conda.  The example is building a container for idba - a genome assembler.  Idba is available in bioconda, but not as a biocontainer.  We'll build this container locally to match a local conda environment, then run it on the HPC and do an example assembly.</p>
<h4 id="locally">Locally<a class="headerlink" href="#locally" title="Permanent link">¶</a></h4>
<p>Make sure you have conda setup on your local machine, anaconda and miniconda are good choices.  Create a new conda environment and install idba</p>
<div class="highlight"><pre><span></span><code>conda create --name idba
conda install -c bioconda idba
</code></pre></div>
<p>Export your conda environment, we will use this to build the container.
<div class="highlight"><pre><span></span><code>conda env <span class="nb">export</span> &gt; environment.yml
</code></pre></div></p>
<p>We will use a singularity definition, basing our build on a docker miniconda image.  There is a bunch of stuff in this file to make sure the conda environment is in the path. <em><a href="https://stackoverflow.com/questions/54678805/containerize-a-conda-environment-in-a-singularity-container">From stackoverflow</a></em></p>
<p><em>idba.def</em>
<div class="highlight"><pre><span></span><code>Bootstrap: docker

From: continuumio/miniconda3

%files
    environment.yml

%environment
    PATH=/opt/conda/envs/$(head -1 environment.yml | cut -d' ' -f2)/bin:$PATH

%post
    echo ". /opt/conda/etc/profile.d/conda.sh" &gt;&gt; ~/.bashrc
    echo "source activate $(head -1 environment.yml | cut -d' ' -f2)" &gt; ~/.bashrc
    /opt/conda/bin/conda env create -f environment.yml

%runscript
    exec "$@"
</code></pre></div></p>
<p>Build the image
<div class="highlight"><pre><span></span><code>sudo singularity build idba.img idba.def
</code></pre></div></p>
<p>Now copy the idba.img and environment.yml (technically the environment file is not needed, but not having it creates a warning) to somewhere sensible on Rāpoi.</p>
<h4 id="on-rapoi">On Rāpoi<a class="headerlink" href="#on-rapoi" title="Permanent link">¶</a></h4>
<p>Create a data directory, so we can separate our inputs and outputs.  Download a paired end illumina read of Ecoli from S3 with wget.  The data comes from the <a href="https://www.illumina.com/informatics/sequencing-data-analysis/data-examples.html">Illumina public data library</a>
<div class="highlight"><pre><span></span><code>mkdir data
cd data 
wget --content-disposition goo.gl/JDJTaz #sequence data
wget --content-disposition goo.gl/tt9fsn #sequence data
cd ..  #back to our project directory
</code></pre></div></p>
<p>The reads we have are paired end fastq files but idba requires a fasta file.  We can use a tool built into our container to convert them.  We'll do this on the Rāpoi login node as it is a fast task that doesn't need many resources.</p>
<div class="highlight"><pre><span></span><code>module load singularity
singularity <span class="nb">exec</span> fq2fa --merge --filter data/MiSeq_Ecoli_MG1655_50x_R1.fastq data/MiSeq_Ecoli_MG1655_50x_R2.fastq data/read.fa
</code></pre></div>
<p>Create our sbatch submission script.  Note that this sequence doesn't need a lot of memory, so we'll use 1G. To see your usage after the job has run use <code>vuw-job-report &lt;job-id&gt;</code></p>
<p><em>idba_submit.sh</em>
<div class="highlight"><pre><span></span><code><span class="ch">#!/bin/bash</span>

<span class="c1">#SBATCH --job-name=idba_test</span>
<span class="c1">#SBATCH -o output.out</span>
<span class="c1">#SBATCH -e output.err</span>
<span class="c1">#SBATCH --time=00:10:00</span>
<span class="c1">#SBATCH --partition=quicktest</span>
<span class="c1">#SBATCH --ntasks=12</span>
<span class="c1">#SBATCH --mem=1G</span>

module load singularity

singularity <span class="nb">exec</span> idba.img idba idba_ud -r data/read.fa -o output
</code></pre></div></p>
<p>Now we can submit our script to the queue with
<div class="highlight"><pre><span></span><code>sbatch idba_submit.sh 
</code></pre></div></p>
</div>
</div><footer>
<div aria-label="Footer Navigation" class="rst-footer-buttons" role="navigation">
<a class="btn btn-neutral float-left" href="../notebooks/" title="Using Jupyter Notebooks"><span class="icon icon-circle-arrow-left"></span> Previous</a>
<a class="btn btn-neutral float-right" href="../training/" title="Training">Next <span class="icon icon-circle-arrow-right"></span></a>
</div>
<hr/>
<div role="contentinfo">
<!-- Copyright etc -->
</div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
</div>
</div>
</section>
</div>
<div aria-label="Versions" class="rst-versions" role="note">
<span class="rst-current-version" data-toggle="rst-current-version">
<span><a href="../notebooks/" style="color: #fcfcfc">« Previous</a></span>
<span><a href="../training/" style="color: #fcfcfc">Next »</a></span>
</span>
</div>
<script>var base_url = '..';</script>
<script defer="" src="../js/theme_extra.js"></script>
<script defer="" src="../js/theme.js"></script>
<script defer="" src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
<script defer="" src="../search/main.js"></script>
<script defer="">
        window.onload = function () {
            SphinxRtdTheme.Navigation.enable(true);
        };
    </script>
</body>
</html>
